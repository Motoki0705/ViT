import ssl
import certifi

ssl._create_default_https_context = ssl._create_unverified_context

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader
import torchvision
import torchvision.transforms as transforms
import matplotlib.pyplot as plt
from vit import VisionTransformer

# ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†ï¼ˆãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ç”¨ï¼‰
transform_train = transforms.Compose([
    transforms.RandomCrop(32, padding=4),
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.ToTensor(),
    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))
])

# ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†ï¼ˆãƒ†ã‚¹ãƒˆç”¨ï¼‰
transform_eval = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))
])

# CIFAR-10 ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ
train_dataset = torchvision.datasets.CIFAR10('data', train=True, transform=transform_train, download=True)
eval_dataset = torchvision.datasets.CIFAR10('data', train=False, transform=transform_eval, download=True)

# DataLoader
train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4)
eval_dataloader = DataLoader(eval_dataset, batch_size=64, shuffle=False, num_workers=4)

# Vision Transformer ãƒ¢ãƒ‡ãƒ«
ViT = VisionTransformer(
    input_shape=(3, 32, 32),
    patch_size=2,
    dim=512,
    num_class=10,
    num_enc_layers=3,
    num_head=4,
    dropout_rate=0.3
)

# ãƒ‡ãƒã‚¤ã‚¹è¨­å®š (CUDA or CPU)
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
ViT.to(device)

# æå¤±é–¢æ•° & æœ€é©åŒ–æ‰‹æ³•
criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(ViT.parameters(), lr=3e-4)  # åˆæœŸå­¦ç¿’ç‡

# å­¦ç¿’ç‡ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ (10ã‚¨ãƒãƒƒã‚¯ã”ã¨ã«å­¦ç¿’ç‡ã‚’ 0.1å€)
scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)

# ã‚¢ãƒ¼ãƒªãƒ¼ã‚¹ãƒˆãƒƒãƒ”ãƒ³ã‚°ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
early_stopping_patience = 5
best_acc = 0.0
epochs_no_improve = 0

# è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®è¨˜éŒ²ç”¨
train_losses, eval_losses = [], []
train_accs, eval_accs = [], []

# è¨“ç·´ & è©•ä¾¡ãƒ«ãƒ¼ãƒ—
Epochs = 30
for epoch in range(Epochs):
    epoch_loss = 0
    correct, total = 0, 0

    ViT.train()
    for img, target in train_dataloader:
        img, target = img.to(device), target.to(device)

        # é †ä¼æ’­
        out = ViT(img)
        train_loss = criterion(out, target)

        # é€†ä¼æ’­
        optimizer.zero_grad()
        train_loss.backward()
        optimizer.step()

        epoch_loss += train_loss.item()

        # ç²¾åº¦è¨ˆç®—
        _, predicted = out.max(1)
        total += target.size(0)
        correct += predicted.eq(target).sum().item()

    train_acc = 100. * correct / total
    train_losses.append(epoch_loss / len(train_dataloader))
    train_accs.append(train_acc)

    print(f"[Epoch {epoch+1}/{Epochs}] Train Loss: {train_losses[-1]:.4f}, Train Acc: {train_acc:.2f}%")

    # **è©•ä¾¡ï¼ˆæ¤œè¨¼ï¼‰**
    ViT.eval()
    eval_loss = 0
    correct, total = 0, 0

    with torch.no_grad():
        for img, target in eval_dataloader:
            img, target = img.to(device), target.to(device)

            out = ViT(img)
            loss = criterion(out, target)
            eval_loss += loss.item()

            # ç²¾åº¦è¨ˆç®—
            _, predicted = out.max(1)
            total += target.size(0)
            correct += predicted.eq(target).sum().item()

    eval_acc = 100. * correct / total
    eval_losses.append(eval_loss / len(eval_dataloader))
    eval_accs.append(eval_acc)

    print(f"[Epoch {epoch+1}/{Epochs}] Eval Loss: {eval_losses[-1]:.4f}, Eval Acc: {eval_acc:.2f}%")

    # **æœ€é«˜ç²¾åº¦ã®ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜**
    if eval_acc > best_acc:
        best_acc = eval_acc
        epochs_no_improve = 0
        torch.save(ViT.state_dict(), "best_model.pth")
        print(f"âœ… Model saved with Accuracy: {best_acc:.2f}%")
    else:
        epochs_no_improve += 1
        print(f"âš ï¸ No improvement for {epochs_no_improve} epoch(s)")

    # **ã‚¢ãƒ¼ãƒªãƒ¼ã‚¹ãƒˆãƒƒãƒ”ãƒ³ã‚°**
    if epochs_no_improve >= early_stopping_patience:
        print("â¹ï¸ Early Stopping triggered! Stopping training.")
        break

    # å­¦ç¿’ç‡ã‚’æ›´æ–°
    scheduler.step()

print("ğŸ‰ Training Complete!")

# **æå¤± & ç²¾åº¦ã®æ¨ç§»ã‚’ä¿å­˜**
import pandas as pd
history = pd.DataFrame({
    "train_loss": train_losses,
    "eval_loss": eval_losses,
    "train_acc": train_accs,
    "eval_acc": eval_accs
})
history.to_csv("training_history.csv", index=False)
print("ğŸ“Š Training history saved to training_history.csv")

# **æå¤±ã¨ç²¾åº¦ã®æ¨ç§»ã‚’ãƒ—ãƒ­ãƒƒãƒˆ**
plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)
plt.plot(train_losses, label="Train Loss")
plt.plot(eval_losses, label="Eval Loss")
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.title("Loss Curve")
plt.legend()

plt.subplot(1, 2, 2)
plt.plot(train_accs, label="Train Acc")
plt.plot(eval_accs, label="Eval Acc")
plt.xlabel("Epochs")
plt.ylabel("Accuracy (%)")
plt.title("Accuracy Curve")
plt.legend()

plt.savefig("training_curve.png")
plt.show()
